{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQKQQwsdFEbq"
      },
      "source": [
        "# AI CUP 2022: Argument Detection\n",
        "Meng-Chieh, Liu  \n",
        "2022/11/28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVO5UoB1L_nT"
      },
      "source": [
        "## Note\n",
        "\n",
        "1. shared Bert layers --> seperate Bert layers? (√)\n",
        "2. (s+q), (s+r) encoder? (√)\n",
        "3. smaller batch size/ smaller learning rate? (?)\n",
        "4. higher loss weight? (?)\n",
        "5. remove html tokens (√)\n",
        "6. summarization in long text and long sentence (?)\n",
        "7. split long sentences (?)\n",
        "8. freeze less layers? (?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u14qgGoGMYg3"
      },
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnqDRgxNGBFT"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drr_teCsE_Q6",
        "outputId": "0e8239ee-0371-424d-8bc4-e625beed1f75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YkuEVyd3Hn3G"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch pytorch-lightning\n",
        "!pip install -q transformers\n",
        "!pip install -q nltk==3.7\n",
        "!pip install -q bert-extractive-summarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtsUOLW4G3Ur",
        "outputId": "5bed3823-2702-4560-f078-ab960ed7daa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Import all libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Huggingface transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "from torch import nn, cuda\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "%matplotlib inline\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "punctuations = '''!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~'''\n",
        "\n",
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "RANDOM_SEED = 666\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "version = 'v4'\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hVqLIFfdClWY"
      },
      "outputs": [],
      "source": [
        "# normal LCS\n",
        "def LCS(text1: str, text2: str) -> int:\n",
        "\n",
        "    text1 = [i for i in word_tokenize(text1) if len(i)>1 or i not in punctuations]\n",
        "    len_text1 = len(text1)\n",
        "    if len_text1 == 0:\n",
        "      return 0\n",
        "\n",
        "    text2 = [i for i in word_tokenize(text2) if len(i)>1 or i not in punctuations]\n",
        "\n",
        "    if len(text2) > len(text1):\n",
        "        text1, text2 = text2, text1\n",
        "    lcs = [[0]*(len(text2)+1) for _ in range(2)]\n",
        "    for i in range(1, len(text1)+1):\n",
        "        for j in range(1, len(text2)+1):\n",
        "            if text1[i-1]== text2[j-1]:\n",
        "                lcs[i%2][j] = lcs[(i-1) % 2][j-1] +1\n",
        "            else:\n",
        "                lcs[i%2][j]= max(lcs[(i-1)%2][j], lcs[i % 2][j-1])\n",
        "    lcs = lcs[len(text1)% 2][len(text2)]\n",
        "    return lcs/len_text1\n",
        "\n",
        "\n",
        "# 評分用LCS\n",
        "def LCS_Score(text1: str, text2: str) -> int:\n",
        "\n",
        "    text1 = [i for i in word_tokenize(text1) if len(i)>1 or i not in punctuations]\n",
        "    text2 = [i for i in word_tokenize(text2) if len(i)>1 or i not in punctuations]\n",
        "\n",
        "    if len(text2) > len(text1):\n",
        "        text1, text2 = text2, text1\n",
        "    lcs = [[0]*(len(text2)+1) for _ in range(2)]\n",
        "    for i in range(1, len(text1)+1):\n",
        "        for j in range(1, len(text2)+1):\n",
        "            if text1[i-1]== text2[j-1]:\n",
        "                lcs[i%2][j] = lcs[(i-1) % 2][j-1] +1\n",
        "            else:\n",
        "                lcs[i%2][j]= max(lcs[(i-1)%2][j], lcs[i % 2][j-1])\n",
        "    lcs = lcs[len(text1)% 2][len(text2)]\n",
        "    return  lcs / (len(text1) + len(text2) - lcs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cklXl-OKeW3K"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8ktHvQFFamA"
      },
      "source": [
        "### load and filter csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L6zksBM6HYhH"
      },
      "outputs": [],
      "source": [
        "# # load csv\n",
        "# train_path = \"/content/drive/Shareddrives/AI_CUP_NLP/Batch_answers - train_data (no-blank).csv\"\n",
        "# train_data = pd.read_csv(train_path, encoding = \"utf-8\", index_col='id').iloc[:,:5].applymap(lambda x: x.strip('\"')).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WqhT9QM-UU4k"
      },
      "outputs": [],
      "source": [
        "# train_data[\"length\"] = train_data[\"q'\"] + train_data[\"r'\"]\n",
        "# train_data[\"length\"] = train_data[\"length\"].map(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FN21wELTjjIz"
      },
      "outputs": [],
      "source": [
        "# # target sample size\n",
        "# train_data.groupby(by=train_data.id).first().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zcZWXc-vJvpS"
      },
      "outputs": [],
      "source": [
        "# idx = train_data.groupby(by=train_data.id)['length'].transform(max) == train_data['length']\n",
        "# small_train_data = train_data[idx].set_index(\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8QY5Bq52juNl"
      },
      "outputs": [],
      "source": [
        "# small_train_data = small_train_data.groupby(by=small_train_data.index).first()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V9C1uVMEq4_o"
      },
      "outputs": [],
      "source": [
        "# small_train_data['q_length'] = small_train_data['q'].map(len)\n",
        "# small_train_data['r_length'] = small_train_data['r'].map(len)\n",
        "# small_train_data['s'] = small_train_data['s'].map(lambda x: 1 if x==\"AGREE\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bnv6e_Q0ilie"
      },
      "outputs": [],
      "source": [
        "# # check sample size\n",
        "# small_train_data.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A3Br1v20KoT3"
      },
      "outputs": [],
      "source": [
        "# # Save\n",
        "# with open('/content/drive/Shareddrives/AI_CUP_NLP/small_train_data.pickle', 'wb') as f:\n",
        "#     pickle.dump(small_train_data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q7pqLt6AKqmD"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_{version}/small_train_data.pickle', 'rb') as f:\n",
        "    small_train_data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove html token"
      ],
      "metadata": {
        "id": "w6D8O2irsR2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import re"
      ],
      "metadata": {
        "id": "jiMxU7lCt3c-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def regex_remove(text):\n",
        "#   text = re.sub(\"& #? ?[a-zA-Z\\d]{2,8} ; \", '', text)\n",
        "#   text = re.sub(\"-- -- \", '', text)\n",
        "#   return text"
      ],
      "metadata": {
        "id": "eJQ6BxpNsXdg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regex_data = small_train_data.copy()\n",
        "# regex_data['q'] = regex_data['q'].map(regex_remove)\n",
        "# regex_data['r'] = regex_data['r'].map(regex_remove)"
      ],
      "metadata": {
        "id": "Xu7uivmItsmF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save\n",
        "# with open('/content/drive/Shareddrives/AI_CUP_NLP/regex_data.pickle', 'wb') as f:\n",
        "#     pickle.dump(regex_data, f)"
      ],
      "metadata": {
        "id": "-zO3Ks1dtt2_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_{version}/regex_data.pickle', 'rb') as f:\n",
        "    regex_data = pickle.load(f)"
      ],
      "metadata": {
        "id": "S4GV-R3ntv5b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bTF5MHEyxtM"
      },
      "source": [
        "### sentencize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mXh_7zTonFFw"
      },
      "outputs": [],
      "source": [
        "# sentencizer = spacy.load('en_core_web_sm')\n",
        "\n",
        "# def sentencize(sentence):\n",
        "#   return [str(sent) for sent in sentencizer(sentence).sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "e9ciCpi1iYMl"
      },
      "outputs": [],
      "source": [
        "# texts = regex_data[['q', 'r', \"q'\", \"r'\"]]\n",
        "# texts = texts.applymap(sentencize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hyvTv_4s3SdY"
      },
      "outputs": [],
      "source": [
        "# # Save\n",
        "# with open('/content/drive/Shareddrives/AI_CUP_NLP/texts.pickle', 'wb') as f:\n",
        "#     pickle.dump(texts, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "4GQ2Mxj5NO2I"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_{version}/texts.pickle', 'rb') as f:\n",
        "    texts = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O7BRI6Jyq4s"
      },
      "source": [
        "### extractive summary (shorten)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "J_dd2rBj-jBB"
      },
      "outputs": [],
      "source": [
        "# bert_summarizer = Summarizer()\n",
        "\n",
        "# def bert_summarize(sentence):\n",
        "#   if len(sentence) > 1000:\n",
        "#     bert_summary = ''.join(bert_summarizer(sentence, num_sentences=10))\n",
        "#     if bert_summary != \"\":\n",
        "#       return bert_summary\n",
        "#   return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sSBgRMoPzBj0"
      },
      "outputs": [],
      "source": [
        "# summary = regex_data[['q', 'r']]\n",
        "# summary = summary.applymap(bert_summarize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vQchlqXEFwa0"
      },
      "outputs": [],
      "source": [
        "# # Save\n",
        "# with open('/content/drive/Shareddrives/AI_CUP_NLP/summary.pickle', 'wb') as f:\n",
        "#     pickle.dump(summary, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9Qb7eITiGBGs"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_{version}/summary.pickle', 'rb') as f:\n",
        "    summary = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrYE0LbFRnc"
      },
      "source": [
        "### reformat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "f8rhWFRNNmZ7"
      },
      "outputs": [],
      "source": [
        "# reformat_df = pd.DataFrame(columns=['id','sentence', 'is_q', 'label'])\n",
        "\n",
        "# for i in tqdm(small_train_data.index):\n",
        "#   if len(texts[\"q'\"][i]) == 0 or len(texts[\"r'\"][i]) == 0:\n",
        "#     continue\n",
        "  \n",
        "#   ### Q ###\n",
        "#   temp_df = pd.DataFrame(columns=['id', 'sentence', 'is_q', 'label'])\n",
        "#   temp_df['sentence'] = texts['q'][i]\n",
        "#   temp_df['is_q'] = 1\n",
        "#   temp_df[\"id\"] = i\n",
        "  \n",
        "#   if len(texts['q'][i]) == len(texts[\"q'\"][i]):\n",
        "#     temp_df['label'] = 1\n",
        "#   else:\n",
        "#     label_list = []\n",
        "#     for sentence in texts['q'][i]:\n",
        "#       if LCS(sentence, small_train_data[\"q'\"][i]) >= 0.7:\n",
        "#         label_list.append(1)\n",
        "#       else:\n",
        "#         label_list.append(0)\n",
        "#     temp_df['label'] = label_list\n",
        "\n",
        "#   reformat_df = pd.concat([reformat_df, temp_df], axis=0)\n",
        "\n",
        "#   ### R ###\n",
        "#   temp_df = pd.DataFrame(columns=['id', 'sentence', 'is_q', 'label'])\n",
        "#   temp_df['sentence'] = texts['r'][i]\n",
        "#   temp_df['is_q'] = 0\n",
        "#   temp_df[\"id\"] = i\n",
        "\n",
        "#   if len(texts['r'][i]) == len(texts[\"r'\"][i]):\n",
        "#     temp_df['label'] = 1\n",
        "\n",
        "#   else:\n",
        "#     label_list = []\n",
        "#     for sentence in texts['r'][i]:\n",
        "#       if LCS(sentence, small_train_data[\"r'\"][i]) >= 0.7:\n",
        "#         label_list.append(1)\n",
        "#       else:\n",
        "#         label_list.append(0)\n",
        "#     temp_df['label'] = label_list\n",
        "  \n",
        "#   reformat_df = pd.concat([reformat_df, temp_df], axis=0)\n",
        "  \n",
        "# reformat_df = reformat_df.set_index('id', drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "S_HUQZy0ekM9"
      },
      "outputs": [],
      "source": [
        "# # Save\n",
        "# with open('/content/drive/Shareddrives/AI_CUP_NLP/reformat_df.pickle', 'wb') as f:\n",
        "#     pickle.dump(reformat_df, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "88AKr88_exwb"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_{version}/reformat_df.pickle', 'rb') as f:\n",
        "    reformat_df = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoItcTDkX_l4"
      },
      "source": [
        "### combine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "OoSjDa3Orgz7"
      },
      "outputs": [],
      "source": [
        "# combine regex_data, summary and new_df\n",
        "df_1 = regex_data.copy()\n",
        "df_1['q'] = summary['q']\n",
        "df_1['r'] = summary['r']\n",
        "new_df = pd.merge(reformat_df, df_1, how=\"left\", left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCYzm9u-Lit2",
        "outputId": "d7dade27-b10f-4dfc-bc36-0de78007f974"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45591411510608565"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "sum(new_df['label'])/len(new_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y6Lygj_YcEc"
      },
      "source": [
        "### split train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nU5XoAZHvlYC"
      },
      "outputs": [],
      "source": [
        "index = new_df.index.unique()\n",
        "train_index, test_index = train_test_split(index, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)\n",
        "train_index, val_index = train_test_split(train_index, test_size=0.1, random_state=RANDOM_SEED, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WE8fzBkoqeIg"
      },
      "outputs": [],
      "source": [
        "def x_y_split(df_index, new_df, train=False):\n",
        "  df = new_df.loc[df_index]\n",
        "  if train:\n",
        "    df = shuffle(df, random_state=RANDOM_SEED)\n",
        "  X = df[['sentence','q','r','q_length','r_length','is_q']]\n",
        "  y = df[['label','s']]\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "srZ0d7wwwFzu"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = x_y_split(train_index, new_df, train=True)\n",
        "X_val, y_val = x_y_split(val_index, new_df)\n",
        "X_test, y_test = x_y_split(test_index, new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DLodHeTtKw5",
        "outputId": "ad87832c-d99c-4d65-ae2b-c89660d99de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50964, 6), (5617, 6), (6387, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CesZxpPYYgMm"
      },
      "source": [
        "### normalize feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "AGUTGIToKQJt"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "def length_scaler(X, train=False):\n",
        "  if train:\n",
        "    length_feature = scaler.fit_transform(X[['q_length', 'r_length']])\n",
        "  else:\n",
        "    length_feature = scaler.transform(X[['q_length', 'r_length']])\n",
        "  X['q_length'] = length_feature[:,0]\n",
        "  X['r_length'] = length_feature[:,1]\n",
        "  return X\n",
        "\n",
        "X_train = length_scaler(X_train, train=True)\n",
        "X_val = length_scaler(X_val)\n",
        "X_test = length_scaler(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH-IFwWYFJjg"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSRIVzIGOYw2"
      },
      "source": [
        "### parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "VjvR_G3FTNYH"
      },
      "outputs": [],
      "source": [
        "# Initialize the parameters that will be use for training\n",
        "N_EPOCHS = 20\n",
        "BATCH_SIZE = 4\n",
        "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
        "MAX_LEN = 512\n",
        "LR = 2e-4\n",
        "DROPOUT_RATE = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "gRsh1oLGLcDM"
      },
      "outputs": [],
      "source": [
        "BERT_MODEL_NAME = \"bert-base-uncased\" # we will use the BERT base model(the smaller one)\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuDj9EV0Ofqe"
      },
      "source": [
        "### model class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EMl3qHapKMYt"
      },
      "outputs": [],
      "source": [
        "class bertDataset (Dataset):\n",
        "    def __init__(self, X, y, tokenizer, max_len=MAX_LEN):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.q = list(X[\"q\"])\n",
        "        self.r = list(X[\"r\"])\n",
        "        self.sentence = list(X[\"sentence\"])\n",
        "        self.length = len(self.sentence)\n",
        "        self.features = torch.FloatTensor(np.array(X[['q_length', 'r_length', 'is_q']], dtype=np.float32))\n",
        "        self.label = torch.LongTensor(np.array(y['label'], dtype=np.int16).reshape(self.length, 1))\n",
        "        self.s = torch.LongTensor(np.array(y['s'], dtype=np.int16).reshape(self.length, 1))\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        sentence_q = self.tokenizer.encode_plus(\n",
        "            self.sentence[item_idx],\n",
        "            self.q[item_idx],\n",
        "            add_special_tokens = True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        sentence_r = self.tokenizer.encode_plus(\n",
        "            self.sentence[item_idx],\n",
        "            self.r[item_idx],\n",
        "            add_special_tokens=True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "\n",
        "        # sentence = self.tokenizer.encode_plus(\n",
        "            \n",
        "        #     add_special_tokens=True, \n",
        "        #     max_length= self.max_len,\n",
        "        #     padding = 'max_length',\n",
        "        #     return_attention_mask= True, \n",
        "        #     truncation=True,\n",
        "        #     return_tensors = 'pt'\n",
        "        #   )\n",
        "\n",
        "        \n",
        "        return {\n",
        "            'sentence_q': (sentence_q['input_ids'].flatten(), sentence_q['attention_mask'].flatten(), sentence_q['token_type_ids'].flatten()),\n",
        "            'sentence_r': (sentence_r['input_ids'].flatten(), sentence_r['attention_mask'].flatten(), sentence_r['token_type_ids'].flatten()),\n",
        "            # 'sentence': (sentence['input_ids'].flatten(), sentence['attention_mask'].flatten()),\n",
        "            'features' : self.features[item_idx],\n",
        "            'label' : self.label[item_idx],\n",
        "            's' : self.s[item_idx]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "k0PlHKNQL_mD"
      },
      "outputs": [],
      "source": [
        "class bertDataModule (pl.LightningDataModule):\n",
        "    \n",
        "    def __init__(self, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val, X_test=X_test, y_test=y_test, tokenizer=tokenizer, batch_size=BATCH_SIZE, max_token_len=MAX_LEN):\n",
        "        super().__init__()\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = bertDataset(X=self.X_train, y=self.y_train, tokenizer=self.tokenizer, max_len=self.max_token_len)\n",
        "        self.val_dataset  = bertDataset(X=self.X_val, y=self.y_val, tokenizer=self.tokenizer, max_len=self.max_token_len)\n",
        "        self.test_dataset  = bertDataset(X=self.X_test, y=self.y_test, tokenizer=self.tokenizer, max_len=self.max_token_len)\n",
        "        \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader (self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader (self.val_dataset,batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader (self.test_dataset,batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "SH8CV0qPTCJL"
      },
      "outputs": [],
      "source": [
        "class bertClassifier(pl.LightningModule):\n",
        "    # Set up the classifier\n",
        "    def __init__(self, lr=LR, dropout_rate=DROPOUT_RATE, maxLength=MAX_LEN, steps_per_epoch=STEPS_PER_EPOCH, n_epochs=N_EPOCHS):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert1 = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "        self.bert2 = BertModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n",
        "        self.lr = lr\n",
        "        self.fc_task1 = nn.Sequential(\n",
        "            nn.Linear(768*3+3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "        self.fc_task2 = nn.Sequential(\n",
        "            nn.Linear(768*3+3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids1, attention_mask1, token_type_ids1, input_ids2, attention_mask2, token_type_ids2, features):\n",
        "        sentence_q = self.bert1(input_ids=input_ids1, attention_mask=attention_mask1, token_type_ids=token_type_ids1).pooler_output\n",
        "        sentence_r = self.bert2(input_ids=input_ids2, attention_mask=attention_mask2, token_type_ids=token_type_ids2).pooler_output\n",
        "        logits = torch.cat([sentence_q, sentence_r, sentence_q*sentence_r, features], 1)\n",
        "        logits1 = self.fc_task1(logits)\n",
        "        logits2 = self.fc_task2(logits)\n",
        "        return logits1, logits2\n",
        "    \n",
        "    \n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids1, attention_mask1, token_type_ids1  = batch['sentence_q']\n",
        "        input_ids2, attention_mask2, token_type_ids2  = batch['sentence_r']\n",
        "        \n",
        "        features = batch['features']\n",
        "        label = batch['label'].squeeze(1)\n",
        "        s = batch['s'].squeeze(1)\n",
        "\n",
        "        logits1, logits2 = self.forward(input_ids1, attention_mask1, token_type_ids1, input_ids2, attention_mask2, token_type_ids2, features)\n",
        "        loss = self.criterion(logits1, label)*2.5 + self.criterion(logits2, s)\n",
        "        self.log('train_loss', loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids1, attention_mask1, token_type_ids1  = batch['sentence_q']\n",
        "        input_ids2, attention_mask2, token_type_ids2  = batch['sentence_r']\n",
        "\n",
        "        features = batch['features']\n",
        "        label = batch['label'].squeeze(1)\n",
        "        s = batch['s'].squeeze(1)\n",
        "\n",
        "        logits1, logits2 = self.forward(input_ids1, attention_mask1, token_type_ids1, input_ids2, attention_mask2, token_type_ids2, features)\n",
        "        loss = self.criterion(logits1, label)*2.5 + self.criterion(logits2, s)\n",
        "        self.log('val_loss', loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids1, attention_mask1, token_type_ids1  = batch['sentence_q']\n",
        "        input_ids2, attention_mask2, token_type_ids2  = batch['sentence_r']\n",
        "\n",
        "        features = batch['features']\n",
        "        label = batch['label'].squeeze(1)\n",
        "        s = batch['s'].squeeze(1)\n",
        "\n",
        "        logits1, logits2 = self.forward(input_ids1, attention_mask1, token_type_ids1, input_ids2, attention_mask2, token_type_ids2, features)\n",
        "        loss = self.criterion(logits1, label)*2.5 + self.criterion(logits2, s)\n",
        "        self.log('test_loss', loss, prog_bar=True, logger=True)\n",
        "        return loss    \n",
        "    \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters() , lr=self.lr)\n",
        "        warmup_steps = self.steps_per_epoch//3\n",
        "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer,warmup_steps,total_steps)\n",
        "\n",
        "        return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLwvGjF3Uo92"
      },
      "source": [
        "## Train\n",
        "remember to revise checkpoint path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformers.logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "DP5CasXZen6l"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JcJYHXyVQ8P"
      },
      "outputs": [],
      "source": [
        "resume_from_checkpoint = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oR_i3FOQUodC"
      },
      "outputs": [],
      "source": [
        "# Instantiate and set up the data_module\n",
        "bert_data_module = bertDataModule()\n",
        "bert_data_module.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WyQLn5amU1gp"
      },
      "outputs": [],
      "source": [
        "model = bertClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbMYu1Lt_7zP"
      },
      "outputs": [],
      "source": [
        "# freeze bert layers\n",
        "for param in model.bert1.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.bert1.encoder.layer[:10].parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.bert2.embeddings.parameters():\n",
        "    param.requires_grad = False\n",
        "for param in model.bert2.encoder.layer[:10].parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-w3wUTmVnEj"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_loss',\n",
        "    filename='{epoch:02d}-{val_loss:.3f}',\n",
        "    save_top_k=3, \n",
        "    mode='min'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REhX4jS4V69g",
        "outputId": "c2902fec-552c-49c8-dd2c-abf2d03b200b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:55: LightningDeprecationWarning: Setting `Trainer(resume_from_checkpoint=)` is deprecated in v1.5 and will be removed in v2.0. Please pass `Trainer.fit(ckpt_path=)` directly instead.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the Model Trainer\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=N_EPOCHS, \n",
        "    accelerator='gpu', \n",
        "    devices=1, \n",
        "    callbacks=[checkpoint_callback], \n",
        "    default_root_dir='/content/drive/Shareddrives/AI_CUP_NLP',\n",
        "    resume_from_checkpoint=resume_from_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAlvFy00bFof"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, bert_data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D-vje_zyC_j"
      },
      "source": [
        "### Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij6-yhSpwCSg"
      },
      "outputs": [],
      "source": [
        "# import tensorboard\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/drive/Shareddrives/AI_CUP_NLP/lightning_logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnlqStegwy60"
      },
      "source": [
        "## Valid/Test\n",
        "remember to revise model path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35U8c6GdHKIZ"
      },
      "source": [
        "### load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "mM3cq4g8G3Kn"
      },
      "outputs": [],
      "source": [
        "model_path = \"/content/drive/Shareddrives/AI_CUP_NLP/logs_v4/version_6/checkpoints/epoch=10-val_loss=1.731.ckpt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DUl96u1QwxeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29df27a9-7fe9-419f-d2af-1eb8a04ce910"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bertClassifier(\n",
              "  (bert1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (bert2): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc_task1): Sequential(\n",
              "    (0): Linear(in_features=2307, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              "  (fc_task2): Sequential(\n",
              "    (0): Linear(in_features=2307, out_features=512, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
              "  )\n",
              "  (criterion): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "model = model.load_from_checkpoint(model_path)\n",
        "model.eval()\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YaF48GiHCx_"
      },
      "source": [
        "### predict function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fRBkpu5-IbR1"
      },
      "outputs": [],
      "source": [
        "def predict(df, dataloader):\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    softmax = nn.Softmax()\n",
        "\n",
        "    label_predict = torch.Tensor().to(device)\n",
        "    s_predict = torch.Tensor().to(device)\n",
        "\n",
        "    for i, batch in enumerate(tqdm(dataloader)):\n",
        "      input_ids1, attention_mask1, token_type_ids1  = batch['sentence_q']\n",
        "      input_ids2, attention_mask2, token_type_ids2  = batch['sentence_r']\n",
        "\n",
        "      features = batch['features']\n",
        "      label = batch['label'].squeeze(1)\n",
        "      s = batch['s'].squeeze(1)\n",
        "\n",
        "      logits1, logits2 = model(input_ids1.to(device), attention_mask1.to(device), token_type_ids1.to(device),\n",
        "                    input_ids2.to(device), attention_mask2.to(device), token_type_ids2.to(device), features.to(device))\n",
        "      logits1 = softmax(logits1)\n",
        "      logits2 = softmax(logits2)\n",
        "\n",
        "      label_predict = torch.concat([label_predict, logits1])\n",
        "      s_predict = torch.concat([s_predict, logits2])\n",
        "\n",
        "\n",
        "  label_predict_np = label_predict.to('cpu').numpy()\n",
        "  s_predict_np = s_predict.to('cpu').numpy()\n",
        "\n",
        "  \n",
        "  df['label_0'] = label_predict_np[:,0]\n",
        "  df['label_1'] = label_predict_np[:,1]\n",
        "  df['s_0'] = s_predict_np[:,0]\n",
        "  df['s_1'] = s_predict_np[:,1]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUgD-4WwI7-H"
      },
      "source": [
        "### val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tRQTKnfsJByn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d295fcd-b7fa-4f11-b7b0-eee0bfbb89fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1405 [00:00<?, ?it/s]<ipython-input-84-b9fd0ed23189>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits1 = softmax(logits1)\n",
            "<ipython-input-84-b9fd0ed23189>:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits2 = softmax(logits2)\n",
            "  3%|▎         | 42/1405 [00:13<05:49,  3.90it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 66%|██████▌   | 928/1405 [04:19<02:14,  3.55it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 83%|████████▎ | 1172/1405 [05:27<01:05,  3.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            " 91%|█████████ | 1275/1405 [05:56<00:36,  3.58it/s]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "100%|██████████| 1405/1405 [06:32<00:00,  3.58it/s]\n"
          ]
        }
      ],
      "source": [
        "val_df = new_df.loc[val_index]\n",
        "val_dataloader = bert_data_module.val_dataloader()\n",
        "val_result = predict(val_df, val_dataloader)\n",
        "val_result.to_csv('/content/drive/Shareddrives/AI_CUP_NLP/answer/val_result.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Bky-Q6AJNOc"
      },
      "source": [
        "### find threshold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_result = pd.read_csv('/content/drive/Shareddrives/AI_CUP_NLP/answer/val_result.csv', index_col='id')"
      ],
      "metadata": {
        "id": "wPV9zImff-bd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "n9d4TTkgLW8L"
      },
      "outputs": [],
      "source": [
        "def evaluate(df, q_threshold=0.5, r_threshold=0.5):\n",
        "\n",
        "  score_list = []\n",
        "  ids = df.index.unique()\n",
        "\n",
        "  for id in ids:\n",
        "\n",
        "    try:\n",
        "      data = df.loc[id]\n",
        "      # q\n",
        "      q = data[data['is_q']==1].reset_index()\n",
        "      q_answer = q[\"q'\"][0]\n",
        "      if len(q)==1:\n",
        "        q_predict = q[\"q\"][0]\n",
        "      else:\n",
        "        q = q[q['label_1']>=q_threshold]\n",
        "        q_predict = \" \".join(q['sentence'])\n",
        "      \n",
        "      q_score = LCS_Score(q_answer, q_predict)\n",
        "\n",
        "      # r\n",
        "      r = data[data['is_q']==0].reset_index()\n",
        "      r_answer = r[\"r'\"][0]\n",
        "      if len(r)==1:\n",
        "        r_predict = r[\"r\"][0]\n",
        "      else:\n",
        "        r = r[r['label_1']>=r_threshold]\n",
        "        r_predict = \" \".join(r['sentence'])\n",
        "      \n",
        "      r_score = LCS_Score(r_answer, r_predict)\n",
        "\n",
        "      # last\n",
        "      score = (q_score+r_score)/2\n",
        "      score_list.append(score)\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  final_score = sum(score_list)/len(score_list)\n",
        "  return final_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "RKobtNBDJXEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c32e19-9be7-4a63-8794-543ed851f66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [01:44<00:00, 20.84s/it]\n"
          ]
        }
      ],
      "source": [
        "best_score = 0\n",
        "best_q_threshold = 0\n",
        "best_r_threshold = 0\n",
        "\n",
        "for q_threshold in tqdm(range(23, 28, 1)):\n",
        "  q_threshold /= 100\n",
        "  for r_threshold in range(23, 28, 1):\n",
        "    r_threshold /= 100 \n",
        "    try:\n",
        "      final_score = evaluate(val_result, q_threshold, r_threshold)\n",
        "      if final_score > best_score:\n",
        "        best_score = final_score\n",
        "        best_q_threshold = q_threshold\n",
        "        best_r_threshold = r_threshold\n",
        "    except:\n",
        "      pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "3RaWgSE_Jccw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528a9269-6478-4aaf-8ee4-c6c1977b0fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7007625613469985, 0.25, 0.23)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "best_score, best_q_threshold, best_r_threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kaNFhQUykHK"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-T0gJvLNzuOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f26805-ff4c-48b7-f8f4-7970af6e53ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/1597 [00:00<?, ?it/s]<ipython-input-62-b9fd0ed23189>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits1 = softmax(logits1)\n",
            "<ipython-input-62-b9fd0ed23189>:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  logits2 = softmax(logits2)\n",
            "100%|██████████| 1597/1597 [07:23<00:00,  3.60it/s]\n"
          ]
        }
      ],
      "source": [
        "test_df = new_df.loc[test_index]\n",
        "test_dataloader = bert_data_module.test_dataloader()\n",
        "test_result = predict(test_df, test_dataloader)\n",
        "test_result.to_csv('/content/drive/Shareddrives/AI_CUP_NLP/answer/test_result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "ENbUZIXkJigj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c252dfba-eb0c-44c6-c778-a04a89ad9c35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7026683752514115"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "evaluate(test_result, 0.25, 0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result"
      ],
      "metadata": {
        "id": "vah1nSfqqbaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model v3\n",
        "\n",
        "model = version_4/checkpoints/epoch=11-val_loss=1.45.ckpt  \n",
        "weight = 2  \n",
        "(val) best_score, best_threshold = 0.6999463597711145, 0.2  \n",
        "(test) score = 0.7031210002892163\n",
        "(public) score = 0.794138\n",
        "\n",
        "\n",
        "\n",
        "### model v4\n",
        "model = "
      ],
      "metadata": {
        "id": "TDDrTqmqteZE"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rnqDRgxNGBFT",
        "cklXl-OKeW3K",
        "ZLrYE0LbFRnc",
        "IH-IFwWYFJjg",
        "5D-vje_zyC_j",
        "CnlqStegwy60"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}