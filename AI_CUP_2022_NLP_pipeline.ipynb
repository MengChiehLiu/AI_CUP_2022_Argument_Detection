{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6nXd-VS5MW2I",
        "OKTblcRVMj0z",
        "F8HRZYaNMdJr",
        "FgNQiJfOneve",
        "KWx77XFxnkFr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI CUP 2022: Argument Detection\n",
        "Meng-Chieh, Liu  \n",
        "2022/11/28"
      ],
      "metadata": {
        "id": "ASslyzLxMRDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Note\n",
        "The columns should contain only q, r and s  \n",
        "\n",
        "q_length, r_length, is_q\n",
        "\n",
        "pipeline (for each data):  . \n",
        "1. read and get length feature\n",
        "2. sentencize\n",
        "3. directly return sentence if count==1\n",
        "4. extractive long sentence\n",
        "5. model predict (batch)\n",
        "\n"
      ],
      "metadata": {
        "id": "6nXd-VS5MW2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "}\n",
        "setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "7sfeFaiD88HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Bghf32hYMmPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58db77fb-9169-450c-d5ad-f808d006f715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import"
      ],
      "metadata": {
        "id": "OKTblcRVMj0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchtext torch pytorch-lightning\n",
        "!pip install -q transformers\n",
        "!pip install -q nltk==3.7\n",
        "!pip install -q bert-extractive-summarizer"
      ],
      "metadata": {
        "id": "ULc2-bFUMomF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193524c5-d78f-4b29-d5fc-5ae26c1b5d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 798 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 512 kB 65.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.8 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Huggingface transformers\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "from torch import nn, cuda\n",
        "from torchmetrics import Accuracy, F1Score\n",
        "from torch.utils.data import DataLoader,Dataset,RandomSampler, SequentialSampler\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "%matplotlib inline\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "punctuations = '''!\"#$%&'()*+, -./:;<=>?@[\\]^_`{|}~'''\n",
        "\n",
        "from summarizer import Summarizer\n",
        "\n",
        "\n",
        "RANDOM_SEED = 666\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "GtzPU9jLMqIK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ec3a4c-b8a6-460a-9fbe-37021e9490a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "F8HRZYaNMdJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_df(df_path):\n",
        "  df = pd.read_csv(df_path, encoding = \"utf-8\", index_col='id')[['q','r','s']].applymap(lambda x: x.strip('\"'))\n",
        "  df['q_length'] = df['q'].map(len)\n",
        "  df['r_length'] = df['r'].map(len)\n",
        "  return df"
      ],
      "metadata": {
        "id": "VXqrI7GfMvaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentencize(sentence, model):\n",
        "\n",
        "  return [str(sent) for sent in model(sentence).sents]"
      ],
      "metadata": {
        "id": "ha6zstfbNqIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_summarize(sentence, model, length=2000):\n",
        "  if len(sentence) > 1000:\n",
        "    bert_summary = ''.join(model(sentence, num_sentences=10))\n",
        "    if bert_summary != \"\":\n",
        "      return bert_summary\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "dZ4PfDofN_yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def regex_remove(text):\n",
        "  text = re.sub(\"& #? ?[a-zA-Z\\d]{2,8} ; \", '', text)\n",
        "  text = re.sub(\"-- -- \", '', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "Ju7jGLyjXaSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model"
      ],
      "metadata": {
        "id": "FgNQiJfOneve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class bertDataset (Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.q = list(df[\"q\"])\n",
        "        self.r = list(df[\"r\"])\n",
        "        self.sentence = list(df[\"sentence\"])\n",
        "        self.length = len(self.sentence)\n",
        "        self.features = torch.FloatTensor(np.array(df[['q_length', 'r_length', 'is_q']], dtype=np.float32))\n",
        "        self.max_len = 512\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        sentence_q = self.tokenizer.encode_plus(\n",
        "            self.sentence[item_idx],\n",
        "            self.q[item_idx],\n",
        "            add_special_tokens = True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        sentence_r = self.tokenizer.encode_plus(\n",
        "            self.sentence[item_idx],\n",
        "            self.r[item_idx],\n",
        "            add_special_tokens=True,\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_attention_mask= True,\n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        return {\n",
        "            'sentence_q': (sentence_q['input_ids'].flatten(), sentence_q['attention_mask'].flatten(), sentence_q['token_type_ids'].flatten()),\n",
        "            'sentence_r': (sentence_r['input_ids'].flatten(), sentence_r['attention_mask'].flatten(), sentence_r['token_type_ids'].flatten()),\n",
        "            'features' : self.features[item_idx]\n",
        "        }"
      ],
      "metadata": {
        "id": "yUQ5K8TTsA0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class bertClassifier(pl.LightningModule):\n",
        "    # Set up the classifier\n",
        "    def __init__(self, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert1 = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n",
        "        self.bert2 = BertModel.from_pretrained(\"bert-base-uncased\", return_dict=True)\n",
        "        self.fc_task1 = nn.Sequential(\n",
        "            nn.Linear(768*3+3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "\n",
        "        self.fc_task2 = nn.Sequential(\n",
        "            nn.Linear(768*3+3, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(512, 2)\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids1, attention_mask1, token_type_ids1, input_ids2, attention_mask2, token_type_ids2, features):\n",
        "        sentence_q = self.bert1(input_ids=input_ids1, attention_mask=attention_mask1, token_type_ids=token_type_ids1).pooler_output\n",
        "        sentence_r = self.bert2(input_ids=input_ids2, attention_mask=attention_mask2, token_type_ids=token_type_ids2).pooler_output\n",
        "        logits = torch.cat([sentence_q, sentence_r, sentence_q*sentence_r, features], 1)\n",
        "        logits1 = self.fc_task1(logits)\n",
        "        logits2 = self.fc_task2(logits)\n",
        "        return logits1, logits2"
      ],
      "metadata": {
        "id": "ksZ7caEqncwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### predict"
      ],
      "metadata": {
        "id": "KWx77XFxnkFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(df, model, dataloader):\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    softmax = nn.Softmax()\n",
        "    label_predict = torch.Tensor().to(device)\n",
        "\n",
        "    for i, batch in enumerate(tqdm(dataloader)):\n",
        "      input_ids1, attention_mask1, token_type_ids1  = batch['sentence_q']\n",
        "      input_ids2, attention_mask2, token_type_ids2  = batch['sentence_r']\n",
        "      features = batch['features']\n",
        "\n",
        "      logits1, _ = model(input_ids1.to(device), attention_mask1.to(device), token_type_ids1.to(device),\n",
        "                  input_ids2.to(device), attention_mask2.to(device), token_type_ids2.to(device), features.to(device))\n",
        "      logits1 = softmax(logits1)\n",
        "\n",
        "\n",
        "      label_predict = torch.concat([label_predict, logits1])\n",
        "\n",
        "\n",
        "  label_predict_np = label_predict.to('cpu').numpy()\n",
        "  \n",
        "  df['label_1'] = label_predict_np[:,1]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "sEG-R1UXt3nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reformat(df_answer, df_predict, threshold=0.5):\n",
        "\n",
        "\n",
        "  for id in df_answer.index:\n",
        "\n",
        "    try:\n",
        "      data = df_predict.loc[id]\n",
        "\n",
        "      # q\n",
        "      q = data[(data['is_q']==1)].reset_index()\n",
        "      max_value = q[\"label_1\"].max()\n",
        "\n",
        "      if max_value < threshold:\n",
        "        index = q[q[\"label_1\"]==max_value].index[0]\n",
        "        q_predict = q['sentence'][index]\n",
        "      else:\n",
        "        q = q[q['label_1']>=threshold]\n",
        "        q_predict = \" \".join(q['sentence'])\n",
        "      \n",
        "      df_answer['q'][id] = q_predict\n",
        "\n",
        "\n",
        "      # r\n",
        "      r = data[(data['is_q']==0)].reset_index()\n",
        "      max_value = r[\"label_1\"].max()\n",
        "      \n",
        "      if max_value < threshold:\n",
        "        index = r[r[\"label_1\"]==max_value].index[0]\n",
        "        r_predict = r['sentence'][index]\n",
        "      else:\n",
        "        r = r[r['label_1']>=threshold]\n",
        "        r_predict = \" \".join(r['sentence'])\n",
        "      df_answer['r'][id] = r_predict\n",
        "\n",
        "    except:\n",
        "      print(f'Error in id {id}.')\n",
        "      pass\n",
        "\n",
        "  return df_answer"
      ],
      "metadata": {
        "id": "pa4wZpOCvIGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main func"
      ],
      "metadata": {
        "id": "gqM5k6i7qOWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(df_path, model_path, threshold=0.5):\n",
        "  # load pretrained models\n",
        "  spacy_sentencizer = spacy.load('en_core_web_sm')\n",
        "  # bert_summarizer = Summarizer()\n",
        "  # tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "  # model = bertClassifier()\n",
        "  # model = model.load_from_checkpoint(model_path)\n",
        "  # model.eval()\n",
        "  # model.to(device)\n",
        "\n",
        "\n",
        "  # preprocess\n",
        "  df = read_df(df_path)\n",
        "  df['q'] = df['q'].map(regex_remove)\n",
        "  df['r'] = df['r'].map(regex_remove)\n",
        "  print(\"except length: {}\".format(len(df))) \n",
        "  df[\"q_sentences\"] = df['q'].apply(sentencize, args=[spacy_sentencizer])\n",
        "  df[\"r_sentences\"] = df['r'].apply(sentencize, args=[spacy_sentencizer])\n",
        "  # df[\"q_summary\"] = df['q'].apply(bert_summarize, args=[bert_summarizer])\n",
        "  # df[\"r_summary\"] = df['r'].apply(bert_summarize, args=[bert_summarizer])\n",
        "\n",
        "\n",
        "  # reformat data\n",
        "  df_answer = pd.DataFrame(index=df.index, columns=['q', 'r'])\n",
        "  df_loader = pd.DataFrame(columns=['id','sentence', 'q', 'r', 'is_q', 'q_length', 'r_length'])\n",
        "  for id in df.index:\n",
        "    # Q\n",
        "    # if len(df[\"q_sentences\"]) <= 1:\n",
        "    #   df_answer['q'][id] = df['q'][id]\n",
        "    # else:\n",
        "    if len(df[\"q_sentences\"]) >= 1:\n",
        "      q = pd.DataFrame(columns=['id','sentence', 'q', 'r', 'is_q', 'q_length', 'r_length'])\n",
        "      \n",
        "      q['sentence'] = df[\"q_sentences\"][id]\n",
        "      q['id'] = id\n",
        "      # q['q'] = df[\"q_summary\"][id]\n",
        "      # q['r'] = df[\"r_summary\"][id]\n",
        "      q['is_q'] = 1\n",
        "      q['q_length'] = df[\"q_length\"][id]\n",
        "      q['r_length'] = df[\"r_length\"][id]\n",
        "      df_loader = pd.concat([df_loader, q])\n",
        "\n",
        "    # R\n",
        "    # if len(df[\"r_sentences\"]) <= 1:\n",
        "    #   df_answer['r'][id] = df['r'][id]\n",
        "    # else:\n",
        "    if len(df[\"r_sentences\"]) >= 1:\n",
        "      r = pd.DataFrame(columns=['id','sentence', 'q', 'r', 'is_q', 'q_length', 'r_length'])\n",
        "      \n",
        "      r['sentence'] = df[\"r_sentences\"][id]\n",
        "      r['id'] = id\n",
        "      # r['q'] = df[\"q_summary\"][id]\n",
        "      # r['r'] = df[\"r_summary\"][id]\n",
        "      r['is_q'] = 0\n",
        "      r['q_length'] = df[\"q_length\"][id]\n",
        "      r['r_length'] = df[\"r_length\"][id]\n",
        "      df_loader = pd.concat([df_loader, r])\n",
        "\n",
        "  df_loader = df_loader.set_index('id')  \n",
        "  return df_loader\n",
        "\n",
        "  # model predict\n",
        "  dataset = bertDataset(df=df_loader, tokenizer=tokenizer)\n",
        "  dataloader = DataLoader(dataset, batch_size=16, num_workers=2)\n",
        "  df_predict = predict(df_loader, model, dataloader)\n",
        "\n",
        "  # create answer\n",
        "  df_answer = reformat(df_answer, df_predict, threshold)\n",
        "  print(\"output length: {}\".format(len(df_answer))) \n",
        "\n",
        "  return df_answer"
      ],
      "metadata": {
        "id": "izskDQYxRCFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main"
      ],
      "metadata": {
        "id": "wAFMEj7LhlcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "U3JKMb2383Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load\n",
        "with open(f'/content/drive/Shareddrives/AI_CUP_NLP/data_v3/reformat_df.pickle', 'rb') as f:\n",
        "    reformat_df = pickle.load(f)"
      ],
      "metadata": {
        "id": "Xn83hu4v86VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_1 = reformat_df.copy()\n",
        "res_1['tokens'] = res_1['sentence'].map(bert_token_length)"
      ],
      "metadata": {
        "id": "6-Q8UNka9FHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_1['tokens'].quantile([i/100 for i in range(0,100,1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1gfzreX9PG_",
        "outputId": "b2152e98-0c37-4845-80c8-3881c21f62bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00     3.0\n",
              "0.01     4.0\n",
              "0.02     4.0\n",
              "0.03     4.0\n",
              "0.04     5.0\n",
              "        ... \n",
              "0.95    47.0\n",
              "0.96    50.0\n",
              "0.97    53.0\n",
              "0.98    58.0\n",
              "0.99    68.0\n",
              "Name: tokens, Length: 100, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = res_1[res_1['tokens']>100]"
      ],
      "metadata": {
        "id": "QdqfaGWV9PlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zOA8BfA_9wN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_path=\"/content/drive/Shareddrives/AI_CUP_NLP/Batch_answers - test_data(no_label).csv\"\n",
        "model_path=\"/content/drive/Shareddrives/AI_CUP_NLP/lightning_logs/version_4/checkpoints/epoch=11-val_loss=1.45.ckpt\""
      ],
      "metadata": {
        "id": "9x8o0UgZshKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = main(df_path, model_path, 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOoagY8xRrE_",
        "outputId": "a0bc74d8-1050-47c2-f97e-3dae0e62595d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "except length: 2016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "4bp-D92ZSAVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_token_length(text):\n",
        "  tokens = tokenizer.encode_plus(text, add_special_tokens=True)\n",
        "  return len(tokens['input_ids'])"
      ],
      "metadata": {
        "id": "o_NcgjolR1IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = df_test.copy()\n",
        "res['tokens'] = res['sentence'].map(bert_token_length)"
      ],
      "metadata": {
        "id": "_uHU8ZQOR1DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res['tokens'].quantile([i/100 for i in range(0,100,1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhsockvcXRXV",
        "outputId": "973201e4-08c8-478a-acf6-4611f7808938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00     3.0\n",
              "0.01     4.0\n",
              "0.02     4.0\n",
              "0.03     4.0\n",
              "0.04     5.0\n",
              "        ... \n",
              "0.95    46.0\n",
              "0.96    49.0\n",
              "0.97    52.0\n",
              "0.98    57.0\n",
              "0.99    66.0\n",
              "Name: tokens, Length: 100, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = iter(res[res['tokens']>66]['sentence'].values)"
      ],
      "metadata": {
        "id": "Yd21kDhIYf07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in enumerate(x):\n",
        "  print(i)\n",
        "  print(j)\n",
        "  print('------------------------------')"
      ],
      "metadata": {
        "id": "qXmPdXxmY0nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_answer = main(df_path, model_path, 0.2)"
      ],
      "metadata": {
        "id": "0jq9C7yGpfIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_answer = df_answer.applymap(regex_remove)"
      ],
      "metadata": {
        "id": "rJ29iTRQiVmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_answer.to_csv('/content/drive/Shareddrives/AI_CUP_NLP/answer/model_v3.5.csv')"
      ],
      "metadata": {
        "id": "sfj1hDdl0muu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### other"
      ],
      "metadata": {
        "id": "xMqQAPaOpxIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = read_df(df_path)"
      ],
      "metadata": {
        "id": "8VdvOxUFpyzg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}